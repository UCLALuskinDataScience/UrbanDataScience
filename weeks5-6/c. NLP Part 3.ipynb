{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7853aaf0",
   "metadata": {},
   "source": [
    "# Weeks 5 and 6. Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e9f6b",
   "metadata": {},
   "source": [
    "## Part 3. Sentiment analysis\n",
    "In this notebook, you'll learn to:\n",
    "* Scrape Twitter data using the API\n",
    "* Conduct sentiment analysis of text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505057a",
   "metadata": {},
   "source": [
    "We reviewed topic modeling in a previous notebook. Here, we'll focus on another common Natural Language Processing tool: sentiment analysis. In short, sentiment analysis tries to understand whether a snippet of text (e.g. a tweet, a review, or a sentence from an article) is positive, negative, or neutral.\n",
    "\n",
    "In its simplest form, sentiment analysis works through applying a corpus of words and phrases that indicate sentiment. [SentiWordNet](https://github.com/aesuli/SentiWordNet) is a commonly used corpusâ€”[look at the list here](https://raw.githubusercontent.com/aesuli/SentiWordNet/master/data/SentiWordNet_3.0.0.txt). For example, \"worst,\" \"terrible,\" and \"apprehensive\" have negative scores, while \"feel_like_a_million_dollars\" has a positive score. Some words have both positive and negative scores. Some algorithms consider the part of speech in which the word occurs (e.g. is it an adjective or noun).\n",
    "\n",
    "`nltk` has a lot of advanced sentiment analysis functionality. For simpler cases, however, I find the `textblob` library to be easier to use. You'll also need to install the `tweepy` library to get access to the Twitter data: \n",
    "\n",
    "`conda install tweepy textblob -c conda-forge`. \n",
    "\n",
    "If you want to access the data yourself, also [sign up for a Twitter developer account](https://developer.twitter.com/en/docs/developer-portal/overview), which will give you an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c440448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "# log in via codes provided by Twitter\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "\n",
    "access_token = ''\n",
    "access_token_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0452b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweepy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bdaf7ccd83c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this is for authentication by using OAuthHandler and set_access_token method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from tweepy with a bunch of codes hidden to us\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccess_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_token_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweepy' is not defined"
     ]
    }
   ],
   "source": [
    "# this is for authentication by using OAuthHandler and set_access_token method\n",
    "# from tweepy with a bunch of codes hidden to us\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e001e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweepy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-76d6f5e70c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# main variables where we'll do all the twitter magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweepy' is not defined"
     ]
    }
   ],
   "source": [
    "# main variables where we'll do all the twitter magic\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d014aba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7d8389f71648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create a public var to store a list of tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# .search method will retrieve a bunch of tweets with the designated word (public transit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpublic_tweets_LA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'public transit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeocode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'34.052235,-118.243683,10km'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2020-03-15'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "# create a public var to store a list of tweets\n",
    "# .search method will retrieve a bunch of tweets with the designated word (public transit)\n",
    "public_tweets_LA = api.search('public transit', geocode='34.052235,-118.243683,10km',lang='en', Since='2020-03-15',count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b15faa",
   "metadata": {},
   "source": [
    "Let's explore the `public_tweets_LA` object that we created. It looks like we can iterate over it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b990af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'public_tweets_LA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-213bc80843d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_tweets_LA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'public_tweets_LA' is not defined"
     ]
    }
   ],
   "source": [
    "help(public_tweets_LA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e0676",
   "metadata": {},
   "source": [
    "What does a single tweet look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54f053c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'public_tweets_LA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-39f200f9f85a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublic_tweets_LA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'public_tweets_LA' is not defined"
     ]
    }
   ],
   "source": [
    "tweet = public_tweets_LA[0]\n",
    "print (tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7b811",
   "metadata": {},
   "source": [
    "So now we've figured out that we can iterate (loop) over the tweets, and use the `text` attribute to get the content. There are other attributes too, but let's not worry about them for now.\n",
    "\n",
    "Let's turn to sentiment analysis. `textblob` uses the `corpora` from the `nltk` library. We already downloaded a couple of corpora, but we need two more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4302379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/adammb/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/adammb/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e7592",
   "metadata": {},
   "source": [
    "Let's try some examples. Note from the docs: \n",
    "\n",
    "* The sentiment property returns a named tuple of the form `Sentiment(polarity, subjectivity)`. \n",
    "* The polarity score is a float within the range [-1.0, 1.0].\n",
    "* The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b35bb6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.25, subjectivity=0.3333333333333333)\n"
     ]
    }
   ],
   "source": [
    "# examples from the textblob docs: \n",
    "# https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis\n",
    "\n",
    "sentence = TextBlob('I love riding public transit')\n",
    "print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74444b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.0022727272727272783, subjectivity=0.2452020202020202)\n"
     ]
    }
   ],
   "source": [
    "sentence = TextBlob('My bus was late AGAIN today.')\n",
    "print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae64a2",
   "metadata": {},
   "source": [
    "We can access the polarity score directly. (Let's ignore subjectivity.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8416060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b8249",
   "metadata": {},
   "source": [
    "Now let's come back to our tweets. We can compute the sentiment (polarity) score for each tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde08c08",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Write a function that returns the polarity for a given tweet object.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f04014ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "def get_sentiment(tweet):\n",
    "    sentence = tweet.text\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a83cbd",
   "metadata": {},
   "source": [
    "Now, we can apply this function to all of the tweets in our dataset.\n",
    "\n",
    "We could create a `pandas.DataFrame` and use `apply`. But in this instance, it's probably easier to create a list of sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e94e06c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'public_tweets_LA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7421c82b838d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpublic_tweets_LA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'public_tweets_LA' is not defined"
     ]
    }
   ],
   "source": [
    "sentiments_la = [get_sentiment(tweet) for tweet in public_tweets_LA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c62077",
   "metadata": {},
   "source": [
    "Now let's visualize it. A histogram seems appropriate here.\n",
    "\n",
    "Note that the seaborn `histplot` can take a list or any other sequence, as well as a `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa7b3b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function histplot in module seaborn.distributions:\n",
      "\n",
      "histplot(data=None, *, x=None, y=None, hue=None, weights=None, stat='count', bins='auto', binwidth=None, binrange=None, discrete=None, cumulative=False, common_bins=True, common_norm=True, multiple='layer', element='bars', fill=True, shrink=1, kde=False, kde_kws=None, line_kws=None, thresh=0, pthresh=None, pmax=None, cbar=False, cbar_ax=None, cbar_kws=None, palette=None, hue_order=None, hue_norm=None, color=None, log_scale=None, legend=True, ax=None, **kwargs)\n",
      "    Plot univariate or bivariate histograms to show distributions of datasets.\n",
      "    \n",
      "    A histogram is a classic visualization tool that represents the distribution\n",
      "    of one or more variables by counting the number of observations that fall within\n",
      "    disrete bins.\n",
      "    \n",
      "    This function can normalize the statistic computed within each bin to estimate\n",
      "    frequency, density or probability mass, and it can add a smooth curve obtained\n",
      "    using a kernel density estimate, similar to :func:`kdeplot`.\n",
      "    \n",
      "    More information is provided in the :ref:`user guide <tutorial_hist>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : :class:`pandas.DataFrame`, :class:`numpy.ndarray`, mapping, or sequence\n",
      "        Input data structure. Either a long-form collection of vectors that can be\n",
      "        assigned to named variables or a wide-form dataset that will be internally\n",
      "        reshaped.\n",
      "    x, y : vectors or keys in ``data``\n",
      "        Variables that specify positions on the x and y axes.\n",
      "    hue : vector or key in ``data``\n",
      "        Semantic variable that is mapped to determine the color of plot elements.\n",
      "    weights : vector or key in ``data``\n",
      "        If provided, weight the contribution of the corresponding data points\n",
      "        towards the count in each bin by these factors.\n",
      "    stat : {\"count\", \"frequency\", \"density\", \"probability\"}\n",
      "        Aggregate statistic to compute in each bin.\n",
      "        \n",
      "        - ``count`` shows the number of observations\n",
      "        - ``frequency`` shows the number of observations divided by the bin width\n",
      "        - ``density`` normalizes counts so that the area of the histogram is 1\n",
      "        - ``probability`` normalizes counts so that the sum of the bar heights is 1\n",
      "    bins : str, number, vector, or a pair of such values\n",
      "        Generic bin parameter that can be the name of a reference rule,\n",
      "        the number of bins, or the breaks of the bins.\n",
      "        Passed to :func:`numpy.histogram_bin_edges`.\n",
      "    binwidth : number or pair of numbers\n",
      "        Width of each bin, overrides ``bins`` but can be used with\n",
      "        ``binrange``.\n",
      "    binrange : pair of numbers or a pair of pairs\n",
      "        Lowest and highest value for bin edges; can be used either\n",
      "        with ``bins`` or ``binwidth``. Defaults to data extremes.\n",
      "    discrete : bool\n",
      "        If True, default to ``binwidth=1`` and draw the bars so that they are\n",
      "        centered on their corresponding data points. This avoids \"gaps\" that may\n",
      "        otherwise appear when using discrete (integer) data.\n",
      "    cumulative : bool\n",
      "        If True, plot the cumulative counts as bins increase.\n",
      "    common_bins : bool\n",
      "        If True, use the same bins when semantic variables produce multiple\n",
      "        plots. If using a reference rule to determine the bins, it will be computed\n",
      "        with the full dataset.\n",
      "    common_norm : bool\n",
      "        If True and using a normalized statistic, the normalization will apply over\n",
      "        the full dataset. Otherwise, normalize each histogram independently.\n",
      "    multiple : {\"layer\", \"dodge\", \"stack\", \"fill\"}\n",
      "        Approach to resolving multiple elements when semantic mapping creates subsets.\n",
      "        Only relevant with univariate data.\n",
      "    element : {\"bars\", \"step\", \"poly\"}\n",
      "        Visual representation of the histogram statistic.\n",
      "        Only relevant with univariate data.\n",
      "    fill : bool\n",
      "        If True, fill in the space under the histogram.\n",
      "        Only relevant with univariate data.\n",
      "    shrink : number\n",
      "        Scale the width of each bar relative to the binwidth by this factor.\n",
      "        Only relevant with univariate data.\n",
      "    kde : bool\n",
      "        If True, compute a kernel density estimate to smooth the distribution\n",
      "        and show on the plot as (one or more) line(s).\n",
      "        Only relevant with univariate data.\n",
      "    kde_kws : dict\n",
      "        Parameters that control the KDE computation, as in :func:`kdeplot`.\n",
      "    line_kws : dict\n",
      "        Parameters that control the KDE visualization, passed to\n",
      "        :meth:`matplotlib.axes.Axes.plot`.\n",
      "    thresh : number or None\n",
      "        Cells with a statistic less than or equal to this value will be transparent.\n",
      "        Only relevant with bivariate data.\n",
      "    pthresh : number or None\n",
      "        Like ``thresh``, but a value in [0, 1] such that cells with aggregate counts\n",
      "        (or other statistics, when used) up to this proportion of the total will be\n",
      "        transparent.\n",
      "    pmax : number or None\n",
      "        A value in [0, 1] that sets that saturation point for the colormap at a value\n",
      "        such that cells below is constistute this proportion of the total count (or\n",
      "        other statistic, when used).\n",
      "    cbar : bool\n",
      "        If True, add a colorbar to annotate the color mapping in a bivariate plot.\n",
      "        Note: Does not currently support plots with a ``hue`` variable well.\n",
      "    cbar_ax : :class:`matplotlib.axes.Axes`\n",
      "        Pre-existing axes for the colorbar.\n",
      "    cbar_kws : dict\n",
      "        Additional parameters passed to :meth:`matplotlib.figure.Figure.colorbar`.\n",
      "    palette : string, list, dict, or :class:`matplotlib.colors.Colormap`\n",
      "        Method for choosing the colors to use when mapping the ``hue`` semantic.\n",
      "        String values are passed to :func:`color_palette`. List or dict values\n",
      "        imply categorical mapping, while a colormap object implies numeric mapping.\n",
      "    hue_order : vector of strings\n",
      "        Specify the order of processing and plotting for categorical levels of the\n",
      "        ``hue`` semantic.\n",
      "    hue_norm : tuple or :class:`matplotlib.colors.Normalize`\n",
      "        Either a pair of values that set the normalization range in data units\n",
      "        or an object that will map from data units into a [0, 1] interval. Usage\n",
      "        implies numeric mapping.\n",
      "    color : :mod:`matplotlib color <matplotlib.colors>`\n",
      "        Single color specification for when hue mapping is not used. Otherwise, the\n",
      "        plot will try to hook into the matplotlib property cycle.\n",
      "    log_scale : bool or number, or pair of bools or numbers\n",
      "        Set a log scale on the data axis (or axes, with bivariate data) with the\n",
      "        given base (default 10), and evaluate the KDE in log space.\n",
      "    legend : bool\n",
      "        If False, suppress the legend for semantic variables.\n",
      "    ax : :class:`matplotlib.axes.Axes`\n",
      "        Pre-existing axes for the plot. Otherwise, call :func:`matplotlib.pyplot.gca`\n",
      "        internally.\n",
      "    kwargs\n",
      "        Other keyword arguments are passed to one of the following matplotlib\n",
      "        functions:\n",
      "    \n",
      "        - :meth:`matplotlib.axes.Axes.bar` (univariate, element=\"bars\")\n",
      "        - :meth:`matplotlib.axes.Axes.fill_between` (univariate, other element, fill=True)\n",
      "        - :meth:`matplotlib.axes.Axes.plot` (univariate, other element, fill=False)\n",
      "        - :meth:`matplotlib.axes.Axes.pcolormesh` (bivariate)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`matplotlib.axes.Axes`\n",
      "        The matplotlib axes containing the plot.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    displot : Figure-level interface to distribution plot functions.\n",
      "    kdeplot : Plot univariate or bivariate distributions using kernel density estimation.\n",
      "    rugplot : Plot a tick at each observation value along the x and/or y axes.\n",
      "    ecdfplot : Plot empirical cumulative distribution functions.\n",
      "    jointplot : Draw a bivariate plot with univariate marginal distributions.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    \n",
      "    The choice of bins for computing and plotting a histogram can exert\n",
      "    substantial influence on the insights that one is able to draw from the\n",
      "    visualization. If the bins are too large, they may erase important features.\n",
      "    On the other hand, bins that are too small may be dominated by random\n",
      "    variability, obscuring the shape of the true underlying distribution. The\n",
      "    default bin size is determined using a reference rule that depends on the\n",
      "    sample size and variance. This works well in many cases, (i.e., with\n",
      "    \"well-behaved\" data) but it fails in others. It is always a good to try\n",
      "    different bin sizes to be sure that you are not missing something important.\n",
      "    This function allows you to specify bins in several different ways, such as\n",
      "    by setting the total number of bins to use, the width of each bin, or the\n",
      "    specific locations where the bins should break.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    .. include:: ../docstrings/histplot.rst\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "help(sns.histplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sentiments_la)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9021694",
   "metadata": {},
   "source": [
    "What else might we want to do? \n",
    "* We might want to remove retweets if we consider these to be duplicates (although it's not obvious what the best approach is)\n",
    "* Perhaps we want to tokenize into sentences. Otherwise, for longer tweets, the more polarized (opinionated) tweets might be watered down with other sentences.\n",
    "* We might want to compare different transit agencies\n",
    "\n",
    "Retweets can be easily removed. If we look at a few examples, they include the string 'RT @'.\n",
    "\n",
    "And we saw the sentence tokenizer in the last notebook. Here, we take the mean of all sentences in a tweet, but we could also return a list with a polarity for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "633b6db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-dbb3c8a934f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I like riding the bus. Even though it is late every day.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-dbb3c8a934f2>\u001b[0m in \u001b[0;36mget_sentiment\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# returns mean polarity of all sentences in a tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'RT @'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "def get_sentiment(tweet):\n",
    "    # returns mean polarity of all sentences in a tweet\n",
    "    if 'RT @' in tweet.text:\n",
    "        return None \n",
    "    else:\n",
    "        sentences = sent_tokenize(tweet.text)\n",
    "        polarities = [TextBlob(s).sentiment.polarity for s in sentences]\n",
    "        return np.mean(polarities)\n",
    "\n",
    "print(get_sentiment('I like riding the bus. Even though it is late every day.'))\n",
    "sentiments_la = [get_sentiment(tweet) for tweet in public_tweets_LA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e97f3",
   "metadata": {},
   "source": [
    "Finally, let's compare different transit agencies. We have the tweets for LA. What about Houston, and NYC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09a6274a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-cfd0f11435a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# looping over a dictionary yields the key and the value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'public transit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeocode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2020-03-15'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msentiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean sentiment for {}: {.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "# centroids looked up manually\n",
    "centroids = {'LA': '34.052235,-118.243683,10km',\n",
    "             'Houston': '29.749907,-95.358421,10km',\n",
    "             'NYC': '40.7127281,-74.0060152,10km'}\n",
    "\n",
    "# create empty dictionaries to hold the results\n",
    "tweets = {}\n",
    "sentiments = {}\n",
    "\n",
    "for place, centroid in centroids:\n",
    "    # looping over a dictionary yields the key and the value\n",
    "    tweets[place] = api.search('public transit', geocode=centroid, lang='en', Since='2020-03-15',count=100)\n",
    "    sentiments[place] = [get_sentiment(tweet) for tweet in tweets[place]]\n",
    "    print('Mean sentiment for {}: {.2f}'.format(place, np.mean(sentiments['place'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f7ff4",
   "metadata": {},
   "source": [
    "We've already used the `plt.subplots()` function to create a set of axes. However, its real power comes in creating figures with multiple plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a62670a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this creates a 1x3 matrix of plots, and returns a list of axes objects\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "# we can now access each axis as axes[0], axes[1], etc.\n",
    "# or even loop through them as with any other list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be15791",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "# enumerate returns a counter as well as the element of the list\n",
    "for ii, place in enumerate(sentiments.keys()):\n",
    "    sns.histplot(sentiment, ax=axes[ii])\n",
    "    axes[ii].set_title('Sentiments for {}'.format(place))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
